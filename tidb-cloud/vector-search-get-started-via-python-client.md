---
title: Get Started with Vector Search via Python Client
summary: Learn how to quickly get started with the TiDB Vector Search feature via Python Client and perform semantic searches.
---

# Get Started with Vector Search via Python Client

This tutorial will walk you through how to connect to a TiDB cluster via the Python Client, store the vectors from embedding, and perform semantic searches using the vector search feature.

> **Note**
>
> The Vector Search feature is only available for TiDB Serverless at this moment.

## Prerequisites

To complete this tutorial, you need:

- [Python 3.8 or higher](https://www.python.org/downloads/) installed.
- [Git](https://git-scm.com/downloads) installed.
- A TiDB cluster running.

<CustomContent platform="tidb-cloud">

**If you don't have a TiDB cluster, you can create one as follows:**

- Follow [Creating a TiDB Serverless cluster](/develop/dev-guide-build-cluster-in-cloud.md) to create your own TiDB Cloud cluster.

</CustomContent>

## Get Started

You can quickly learn about the Vector Search feature by following the steps below to use the TiDB Vector Python Client.

If you want to run the quick start demo directly, you can check sample code in the [pingcap/tidb-vector-python](https://github.com/pingcap/tidb-vector-python/blob/main/examples/python-client-quickstart ) repository.

### Step 1. Create a new Python project

Create a new Python project in your preferred directory and new a Python file named `example.py`.

```shell
mkdir python-client-quickstart
cd python-client-quickstart
touch example.py
```

### Step 2. Install required dependencies

Run the following command on your project directory to install the required packages:

```shell
pip install sqlalchemy pymysql sentence-transformers tidb-vector
```

- `tidb-vector` is a python client for TiDB Vector feature, which is based on SQLAlchemy.
- `sentence-transformers` is a Python library that provides pre-trained models for generating vector embeddings from text data.

### Step 3. Configure the connection string to the TiDB cluster

<SimpleTab>
<div label="TiDB Serverless">

1. Navigate to the [**Clusters**](https://tidbcloud.com/console/clusters) page, and then click the name of your target cluster to go to its overview page.

2. Click **Connect** in the upper-right corner. A connection dialog is displayed.

3. Ensure the configurations in the connection dialog match your operating environment.

    - **Endpoint Type** is set to `Public`
    - **Branch** is set to `main`
    - **Connect With** is set to `SQLAlchemy`
    - **Operating System** matches your environment.

   > **Tip:**
   >
   > If your program is running in Windows Subsystem for Linux (WSL), switch to the corresponding Linux distribution.

4. Switch the **PyMySQL** tab and click the **Copy** icon to copy the connection string.

   > **Tip:**
   > 
   > If you have not set a password yet, click **Create password** to generate a random password. 

5. Create a `.env` file in your project and paste the connection string into it.

    For example, the connection string on macOS looks like:

    ```dotenv
    TIDB_DATABASE_URL="mysql+pymysql://<prefix>.root:<password>@gateway01.<region>.prod.aws.tidbcloud.com:4000/test?ssl_ca=/etc/ssl/cert.pem&ssl_verify_cert=true&ssl_verify_identity=true"
    ```

</div>

</SimpleTab>

### Step 4. Choose and initialize the embedding model

The [embedding model](/tidb-cloud/vector-search-overview.md#embedding-model) is an algorithm that transforms data into vector embeddings.

In this example, we will download and deploy a pre-trained model **[msmarco-MiniLM-L12-cos-v5](https://huggingface.co/sentence-transformers/msmarco-MiniLM-L12-cos-v5)** for text embedding. **msmarco-MiniLM-L12-cos-v5** is a lightweight model provided by the `sentence-transformers` library, capable of converting text data into 384-dimensional embedding vectors.

Copy the following code to the `example.py` file, it initializes a `SentenceTransformer` instance and define a `text_to_embedding` function for later usage.

```python
from sentence_transformers import SentenceTransformer

print("Downloading and loading the embedding model...")
embed_model = SentenceTransformer("sentence-transformers/msmarco-MiniLM-L12-cos-v5", trust_remote_code=True)
embed_model_dims = embed_model.get_sentence_embedding_dimension()

def text_to_embedding(text):
    """Generates vector embeddings for the given text."""
    embedding = embed_model.encode(text)
    return embedding.tolist()
```

### Step 5. Connect to the TiDB cluster

Use `TiDBVectorClient` to connect to the TiDB cluster and create a data table with a vector column as vector store.

> **Note**
> 
> The dimension of the vector column created should be consistent with the dimension of the vector generated by the embedding model, for example, the vector dimension generated by the **msmarco-MiniLM-L12-cos-v5** model is 384.

```python
import os
from tidb_vector.integrations import TiDBVectorClient
from dotenv import load_dotenv

# Load the connection string from the .env file
load_dotenv()

vector_store = TiDBVectorClient(
   # The table which will store the vector data.
   table_name='embedded_documents',
   # The connection string to the TiDB cluster.
   connection_string=os.environ.get('TIDB_DATABASE_URL'),
   # The dimension of the vector generated by the embedding model.
   vector_dimension=embed_model_dims,
   # Determine whether to recreate the table if it already exists.
   drop_existing_table=True,
)
```

### Step 6. Embed text data and store the vectors

In this example, we prepare several documents with a single word like "dog", "fish", and "tree".

Use the `text_to_embedding` function to transform the texts into embedding vectors and insert them into the vector store.

```python
documents = [
    {
        "id": "f8e7dee2-63b6-42f1-8b60-2d46710c1971",
        "text": "dog",
        "embedding": text_to_embedding("dog"),
        "metadata": {"category": "animal"},
    },
    {
        "id": "8dde1fbc-2522-4ca2-aedf-5dcb2966d1c6",
        "text": "fish",
        "embedding": text_to_embedding("fish"),
        "metadata": {"category": "animal"},
    },
    {
        "id": "e4991349-d00b-485c-a481-f61695f2b5ae",
        "text": "tree",
        "embedding": text_to_embedding("tree"),
        "metadata": {"category": "plant"},
    },
]

vector_store.insert(
    ids=[doc["id"] for doc in documents],
    texts=[doc["text"] for doc in documents],
    embeddings=[doc["embedding"] for doc in documents],
    metadatas=[doc["metadata"] for doc in documents],
)
```

### Step 7. Perform a vector search query

In this example, we try to search query "an swimming animal", which doesn't include any keywords present in the documents. 

Use the `text_to_embedding` function again to convert the query text into an embedding vector, and then query with the embedding to find the top 3 nearest neighbors.

```python
def print_result(query, result):
   print(f"Search result (\"{query}\"):")
   for r in result:
      print(f"- text: \"{r.document}\", distance: {r.distance}")

query = "an swimming animal"
query_embedding = text_to_embedding(query)
search_result = vector_store.query(query_embedding, k=3)
print_result(query, search_result)
```

Run the `example.py` file and you will see the output as follows:

```plain
Search result ("an swimming animal"):
- text: "fish", distance: 0.4586619425596351
- text: "dog", distance: 0.6521646263795423
- text: "tree", distance: 0.7980725077476978
```

Great! The swimming animal is most likely a fish, or a dog with a gift for swimming.

As the results show, we found the most relevant documents through vector search, and the search results are sorted by the distance between the vectors; the closer the distance, the more relevant the document.

## See also

- [Vector Column](/tidb-cloud/vector-search-vector-column.md)
- [Vector HNSW Index](/tidb-cloud/vector-search-vector-hnsw-index.md)